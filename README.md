# Text-generator
# Task01: GPT-2 Emotional Text Generator

This project fine-tunes the GPT-2 model to generate emotionally themed text (e.g., happy, sad, angry). It uses the Hugging Face `transformers` library and runs in a Jupyter/Colab notebook.

## ğŸ“¦ Requirements
Install dependencies using:

## ğŸ“ Files
- `gpt2_generator.ipynb`: Main notebook for training and generation
- `data.txt`: Training data (emotionally themed text)
- `output_samples.txt`: Generated text samples
- `requirements.txt`: Python dependencies

## ğŸš€ Usage
1. Open `gpt2_generator.ipynb` in Colab or Jupyter
2. Run all cells to fine-tune and generate text
3. Modify prompts to explore different emotional outputs
